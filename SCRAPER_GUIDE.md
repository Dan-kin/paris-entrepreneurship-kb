# ç½‘ç«™åˆ†ç±»æ–‡ç« é‡‡é›†å·¥å…·ä½¿ç”¨æŒ‡å—

## åŠŸèƒ½æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ–‡ç« é‡‡é›†å’Œå¤„ç†å·¥å…·ï¼Œå¯ä»¥ï¼š

1. **æŒ‰åˆ†ç±»é‡‡é›†æ–‡ç« ** - ä»ç›®æ ‡ç½‘ç«™è‡ªåŠ¨æŠ“å–æŒ‡å®šåˆ†ç±»çš„æ–‡ç« 
2. **AIæå–è¦ç‚¹** - ä½¿ç”¨AIåˆ†ææ–‡ç« ï¼Œæå–æ ¸å¿ƒè¦ç‚¹å’Œå…³é”®ä¿¡æ¯
3. **AIé‡æ–°æ’°å†™** - åŸºäºè¦ç‚¹é‡æ–°æ’°å†™ï¼Œç¡®ä¿å†…å®¹è´¨é‡å’Œå¯è¯»æ€§
4. **ä¸­æ–‡ç¿»è¯‘** - è‡ªåŠ¨å°†å¤–æ–‡å†…å®¹ç¿»è¯‘ä¸ºç®€ä½“ä¸­æ–‡
5. **ç”ŸæˆMarkdown** - ç”Ÿæˆç¬¦åˆé¡¹ç›®æ ¼å¼çš„Markdownæ–‡ä»¶ï¼Œå¯ç›´æ¥ä½¿ç”¨

## ç›®å½•ç»“æ„

```
src/
â”œâ”€â”€ scraper.py              # ç½‘é¡µæŠ“å–æ¨¡å—
â”œâ”€â”€ ai_processor.py         # AIå¤„ç†æ¨¡å—ï¼ˆæå–ã€æ”¹å†™ã€ç¿»è¯‘ï¼‰
â”œâ”€â”€ content_generator.py    # å†…å®¹ç”Ÿæˆæ¨¡å—
â””â”€â”€ article_scraper.py      # ä¸»ç¨‹åºå…¥å£
```

## å®‰è£…ä¾èµ–

### 1. å®‰è£…PythonåŒ…

```bash
pip install -r requirements.txt
```

æ‰€éœ€ä¾èµ–ï¼š
- `PyYAML` - YAMLå¤„ç†
- `requests` - HTTPè¯·æ±‚
- `beautifulsoup4` - HTMLè§£æ
- `lxml` - XML/HTMLè§£æå™¨
- `openai` - OpenAI APIå®¢æˆ·ç«¯
- `anthropic` - Anthropic Claude APIå®¢æˆ·ç«¯

### 2. é…ç½®APIå¯†é’¥

å¤åˆ¶ç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„APIå¯†é’¥ï¼š

```bash
# ä½¿ç”¨OpenAI
OPENAI_API_KEY=sk-your-openai-api-key

# æˆ–ä½¿ç”¨Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key
```

**æ³¨æ„**ï¼šåªéœ€è¦é…ç½®ä½ ä½¿ç”¨çš„AIæä¾›å•†çš„å¯†é’¥ã€‚

## é…ç½®æ–‡ä»¶

### åˆ›å»ºé…ç½®æ–‡ä»¶

å¤åˆ¶ç¤ºä¾‹é…ç½®ï¼š

```bash
cp scraper_config.example.json scraper_config.json
```

### é…ç½®è¯´æ˜

```json
{
  "website": {
    "base_url": "https://example.com",        // ç›®æ ‡ç½‘ç«™åŸºç¡€URL
    "max_pages": 2,                            // æ¯ä¸ªåˆ†ç±»æœ€å¤šæŠ“å–çš„é¡µæ•°
    "categories": [                            // è¦æŠ“å–çš„åˆ†ç±»åˆ—è¡¨
      {
        "name": "åˆ›ä¸šæ•…äº‹",                    // åˆ†ç±»åç§°
        "url": "https://example.com/startup"  // åˆ†ç±»URL
      }
    ],
    "selectors": {                             // CSSé€‰æ‹©å™¨é…ç½®
      "article_link": "article h2 a",          // æ–‡ç« é“¾æ¥é€‰æ‹©å™¨
      "article_title": "h1.title",             // æ ‡é¢˜é€‰æ‹©å™¨
      "article_content": "article .content",   // å†…å®¹é€‰æ‹©å™¨
      "article_author": ".author",             // ä½œè€…é€‰æ‹©å™¨ï¼ˆå¯é€‰ï¼‰
      "article_date": "time"                   // æ—¥æœŸé€‰æ‹©å™¨ï¼ˆå¯é€‰ï¼‰
    },
    "headers": {                               // HTTPè¯·æ±‚å¤´ï¼ˆå¯é€‰ï¼‰
      "User-Agent": "Mozilla/5.0..."
    }
  },
  "ai": {
    "provider": "openai",                      // AIæä¾›å•†: "openai" æˆ– "anthropic"
    "model": "gpt-4o",                        // æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
    "skip_translation": false                  // æ˜¯å¦è·³è¿‡ç¿»è¯‘
  },
  "output_dir": "content/stories"             // è¾“å‡ºç›®å½•
}
```

### å¦‚ä½•æ‰¾åˆ°æ­£ç¡®çš„CSSé€‰æ‹©å™¨

ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰ï¼š

1. **æ‰¾æ–‡ç« é“¾æ¥é€‰æ‹©å™¨**ï¼š
   - æ‰“å¼€åˆ†ç±»é¡µé¢
   - å³é”®ç‚¹å‡»æ–‡ç« æ ‡é¢˜ â†’ "æ£€æŸ¥å…ƒç´ "
   - æ‰¾åˆ°åŒ…å«æ–‡ç« é“¾æ¥çš„å…ƒç´ 
   - è®°å½•å…¶CSSé€‰æ‹©å™¨ï¼ˆå¦‚ `article h2 a` æˆ– `.post-title a`ï¼‰

2. **æ‰¾å†…å®¹é€‰æ‹©å™¨**ï¼š
   - æ‰“å¼€ä¸€ç¯‡æ–‡ç« 
   - æ‰¾åˆ°æ–‡ç« æ­£æ–‡çš„å®¹å™¨å…ƒç´ 
   - è®°å½•é€‰æ‹©å™¨ï¼ˆå¦‚ `article .content` æˆ– `.post-content`ï¼‰

3. **æµ‹è¯•é€‰æ‹©å™¨**ï¼š
   åœ¨æµè§ˆå™¨æ§åˆ¶å°è¾“å…¥ï¼š
   ```javascript
   document.querySelectorAll('ä½ çš„é€‰æ‹©å™¨')
   ```
   åº”è¯¥èƒ½é€‰ä¸­ç›®æ ‡å…ƒç´ 

## ä½¿ç”¨æ–¹æ³•

### æ–¹å¼1ï¼šæŒ‰é…ç½®æ–‡ä»¶ä¸­çš„æ‰€æœ‰åˆ†ç±»é‡‡é›†

```bash
python src/article_scraper.py -c scraper_config.json -n 10
```

å‚æ•°è¯´æ˜ï¼š
- `-c, --config`: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
- `-n, --num-articles`: æ¯ä¸ªåˆ†ç±»é‡‡é›†çš„æœ€å¤§æ–‡ç« æ•°ï¼ˆé»˜è®¤10ï¼‰
- `-v, --verbose`: æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—

### æ–¹å¼2ï¼šä»æŒ‡å®šURLé‡‡é›†

```bash
python src/article_scraper.py \
  -c scraper_config.json \
  -u "https://example.com/tech-news" \
  --category "ç§‘æŠ€æ–°é—»" \
  -n 5
```

å‚æ•°è¯´æ˜ï¼š
- `-u, --url`: ç›´æ¥æŒ‡å®šURL
- `--category`: åˆ†ç±»åç§°ï¼ˆé»˜è®¤"å…¶ä»–"ï¼‰

### æ–¹å¼3ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡

```bash
# è®¾ç½®APIå¯†é’¥ï¼ˆå¦‚æœæ²¡æœ‰.envæ–‡ä»¶ï¼‰
export OPENAI_API_KEY="sk-your-key"

# è¿è¡Œé‡‡é›†
python src/article_scraper.py -c scraper_config.json
```

## å·¥ä½œæµç¨‹

å·¥å…·çš„å®Œæ•´å¤„ç†æµç¨‹ï¼š

```
1. ç½‘é¡µæŠ“å–
   â”œâ”€â”€ è®¿é—®åˆ†ç±»é¡µé¢
   â”œâ”€â”€ æå–æ–‡ç« é“¾æ¥åˆ—è¡¨
   â””â”€â”€ é€ä¸ªè®¿é—®æ–‡ç« é¡µé¢è·å–å†…å®¹

2. AIå¤„ç†ï¼ˆæ¯ç¯‡æ–‡ç« ï¼‰
   â”œâ”€â”€ æå–è¦ç‚¹ï¼šåˆ†ææ–‡ç« æ ¸å¿ƒä¿¡æ¯
   â”œâ”€â”€ é‡æ–°æ’°å†™ï¼šåŸºäºè¦ç‚¹ç”Ÿæˆæ–°æ–‡ç« 
   â””â”€â”€ ç¿»è¯‘ï¼šç¿»è¯‘ä¸ºä¸­æ–‡ï¼ˆå¦‚éœ€è¦ï¼‰

3. ç”ŸæˆMarkdown
   â”œâ”€â”€ åˆ›å»ºFront Matterï¼ˆå…ƒæ•°æ®ï¼‰
   â”œâ”€â”€ æ ¼å¼åŒ–å†…å®¹
   â”œâ”€â”€ è‡ªåŠ¨æå–æ ‡ç­¾
   â””â”€â”€ ä¿å­˜ä¸º.mdæ–‡ä»¶
```

## è¾“å‡ºæ ¼å¼

ç”Ÿæˆçš„Markdownæ–‡ä»¶æ ¼å¼ï¼š

```markdown
---
id: 1
title: æ–‡ç« æ ‡é¢˜
entrepreneur: ä½œè€…å
company: å…¬å¸åç§°
industry: è¡Œä¸šåˆ†ç±»
founded_year: 2024
location: å·´é»
tags:
  - æ ‡ç­¾1
  - æ ‡ç­¾2
excerpt: æ–‡ç« æ‘˜è¦...
date: 2024-11-11
published: true
source_url: https://åŸæ–‡é“¾æ¥
---

## æ–‡ç« å†…å®¹

é‡æ–°æ’°å†™å’Œç¿»è¯‘åçš„æ–‡ç« å†…å®¹...

---

**åŸæ–‡æ¥æº**: [åŸæ–‡æ ‡é¢˜](åŸæ–‡URL)

**å¤„ç†è¯´æ˜**: æœ¬æ–‡ç”±AIè‡ªåŠ¨é‡‡é›†ã€æå–è¦ç‚¹å¹¶ç¿»è¯‘ç”Ÿæˆã€‚
```

## å®æˆ˜ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šé‡‡é›†TechCrunchåˆ›ä¸šæ•…äº‹

**é…ç½®æ–‡ä»¶** (`techcrunch_config.json`):

```json
{
  "website": {
    "base_url": "https://techcrunch.com",
    "max_pages": 3,
    "categories": [
      {
        "name": "Startups",
        "url": "https://techcrunch.com/category/startups/"
      }
    ],
    "selectors": {
      "article_link": "h2.post-block__title a",
      "article_title": "h1.article__title",
      "article_content": "div.article-content",
      "article_author": "a.article__author-link",
      "article_date": "time.article__date"
    }
  },
  "ai": {
    "provider": "openai",
    "model": "gpt-4o"
  },
  "output_dir": "content/stories"
}
```

**è¿è¡Œå‘½ä»¤**:

```bash
python src/article_scraper.py -c techcrunch_config.json -n 15
```

### ç¤ºä¾‹2ï¼šé‡‡é›†Mediumåˆ›ä¸šæ–‡ç« 

**é…ç½®æ–‡ä»¶** (`medium_config.json`):

```json
{
  "website": {
    "base_url": "https://medium.com",
    "max_pages": 2,
    "categories": [
      {
        "name": "Entrepreneurship",
        "url": "https://medium.com/tag/entrepreneurship"
      }
    ],
    "selectors": {
      "article_link": "article h2 a, div[data-test-id='post-preview-title'] a",
      "article_title": "h1[data-testid='post-title']",
      "article_content": "article section",
      "article_author": "a[data-testid='post-author-name']"
    }
  },
  "ai": {
    "provider": "anthropic",
    "model": "claude-3-5-sonnet-20241022"
  },
  "output_dir": "content/stories"
}
```

### ç¤ºä¾‹3ï¼šå¿«é€Ÿæµ‹è¯•å•ä¸ªURL

```bash
python src/article_scraper.py \
  -c scraper_config.json \
  -u "https://example.com/single-article" \
  --category "æµ‹è¯•" \
  -n 1
```

## å¸¸è§é—®é¢˜

### 1. APIè°ƒç”¨å¤±è´¥

**é”™è¯¯**: `APIè°ƒç”¨å¤±è´¥: Unauthorized`

**è§£å†³**:
- æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„APIå¯†é’¥æ˜¯å¦æ­£ç¡®
- ç¡®è®¤APIå¯†é’¥æœ‰è¶³å¤Ÿçš„é¢åº¦
- æ£€æŸ¥ç½‘ç»œè¿æ¥

### 2. æ— æ³•æŠ“å–æ–‡ç« 

**é”™è¯¯**: `æŠ“å–å¤±è´¥` æˆ– `å‘ç° 0 ç¯‡æ–‡ç« `

**è§£å†³**:
- æ£€æŸ¥CSSé€‰æ‹©å™¨æ˜¯å¦æ­£ç¡®
- ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·éªŒè¯é€‰æ‹©å™¨
- æ£€æŸ¥ç›®æ ‡ç½‘ç«™æ˜¯å¦éœ€è¦ç™»å½•æˆ–æœ‰åçˆ¬è™«æœºåˆ¶
- å°è¯•æ·»åŠ é€‚å½“çš„HTTPå¤´éƒ¨

### 3. å†…å®¹æå–ä¸å®Œæ•´

**è§£å†³**:
- è°ƒæ•´ `article_content` é€‰æ‹©å™¨
- æŸäº›ç½‘ç«™ä½¿ç”¨åŠ¨æ€åŠ è½½ï¼Œå¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†
- æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªå†…å®¹åŒºåŸŸ

### 4. ç¿»è¯‘è´¨é‡ä¸ä½³

**è§£å†³**:
- å°è¯•æ›´æ¢AIæ¨¡å‹ï¼ˆå¦‚ä»GPT-4oåˆ‡æ¢åˆ°Claudeï¼‰
- è°ƒæ•´ `temperature` å‚æ•°ï¼ˆåœ¨ä»£ç ä¸­ï¼‰
- æ£€æŸ¥åŸæ–‡å†…å®¹æ˜¯å¦å®Œæ•´

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰AIå¤„ç†é€»è¾‘

ç¼–è¾‘ `src/ai_processor.py`ï¼Œä¿®æ”¹æç¤ºè¯ï¼š

```python
# ä¿®æ”¹é‡å†™æç¤ºè¯
system_prompt_rewrite = """ä½ çš„è‡ªå®šä¹‰æç¤ºè¯..."""
```

### æ‰¹é‡å¤„ç†å¤šä¸ªç½‘ç«™

åˆ›å»ºè„šæœ¬ `batch_scrape.sh`:

```bash
#!/bin/bash
python src/article_scraper.py -c config1.json -n 10
python src/article_scraper.py -c config2.json -n 10
python src/article_scraper.py -c config3.json -n 10
```

### å®šæ—¶é‡‡é›†

ä½¿ç”¨cronå®šæ—¶è¿è¡Œï¼š

```bash
# æ¯å¤©å‡Œæ™¨2ç‚¹é‡‡é›†
0 2 * * * cd /path/to/project && python src/article_scraper.py -c scraper_config.json -n 5
```

## æœ€ä½³å®è·µ

1. **ç¤¼è²Œé‡‡é›†**ï¼šå·¥å…·å·²å†…ç½®å»¶è¿Ÿï¼Œé¿å…å¯¹ç›®æ ‡ç½‘ç«™é€ æˆè´Ÿæ‹…
2. **æµ‹è¯•é…ç½®**ï¼šå…ˆç”¨ `-n 1` æµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®
3. **æ£€æŸ¥è¾“å‡º**ï¼šé‡‡é›†åæ£€æŸ¥ç”Ÿæˆçš„Markdownæ–‡ä»¶è´¨é‡
4. **APIæˆæœ¬**ï¼šæ³¨æ„AI APIè°ƒç”¨æˆæœ¬ï¼Œåˆç†è®¾ç½®æ–‡ç« æ•°é‡
5. **å¤‡ä»½åŸæ–‡**ï¼šå·¥å…·ä¼šåœ¨æ–‡ç« ä¸­ä¿ç•™åŸæ–‡é“¾æ¥
6. **éµå®ˆrobots.txt**ï¼šå°Šé‡ç½‘ç«™çš„çˆ¬è™«åè®®

## æŠ€æœ¯æ ˆ

- **Python 3.11+**
- **BeautifulSoup4** - HTMLè§£æ
- **Requests** - HTTPå®¢æˆ·ç«¯
- **OpenAI/Anthropic API** - AIå¤„ç†
- **PyYAML** - YAMLå¤„ç†

## å¼€å‘å’Œæ‰©å±•

### æ·»åŠ æ–°çš„AIæä¾›å•†

åœ¨ `src/ai_processor.py` ä¸­æ·»åŠ æ–°çš„æä¾›å•†æ”¯æŒï¼š

```python
elif self.provider == 'your-provider':
    # å®ç°ä½ çš„APIè°ƒç”¨é€»è¾‘
    pass
```

### è‡ªå®šä¹‰å†…å®¹æ ¼å¼

ä¿®æ”¹ `src/content_generator.py` ä¸­çš„ `generate_markdown` æ–¹æ³•ã€‚

## æ•…éšœæ’é™¤

å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼š

```bash
python src/article_scraper.py -c scraper_config.json -v
```

è¿™ä¼šæ˜¾ç¤ºæ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯ï¼Œä¾¿äºè°ƒè¯•ã€‚

## è®¸å¯è¯

æœ¬å·¥å…·éµå¾ªé¡¹ç›®çš„MITè®¸å¯è¯ã€‚

## æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤Issueåˆ°é¡¹ç›®ä»“åº“ã€‚

---

**Happy Scraping!** ğŸš€
